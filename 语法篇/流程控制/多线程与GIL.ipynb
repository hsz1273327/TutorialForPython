{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 多线程与GIL\n",
    "\n",
    "## GIL\n",
    "\n",
    "CPython解释器本身就不是线程安全的,因此有全局解释器锁(GIL),一次只允许使用一个线程执行 Python 字节码.因此一个 Python 进程通常不能同时使用多个 CPU 核心。\n",
    "\n",
    "编写 Python 代码时无法控制 GIL;不过,执行耗时的任务时,可以使用一个内置的函数或一个使用 C 语言编写的扩展释放GIL.其实有个使用 C 语言编写的 Python库能管理GIL,自行启动操作系统线程,利用全部可用的 CPU 核心.这样做会极大地增加库代码的复杂度,因此大多数库的作者都不这么做.\n",
    "\n",
    "然而,标准库中所有执行阻塞型I/O操作的函数,在等待操作系统返回结果时都会释放GIL.这意味着在 Python 语言这个层次上可以使用多线程处理io阻塞问题,而 I/O 密集型 Python 程序能从中受益--一个 Python 线程等待网络响应时,阻塞型 I/O 函数会释放 GIL,再运行一个线程.\n",
    "\n",
    "### 为什么需要GIL\n",
    "\n",
    "GIL是必须的,这是Python设计的问题--Python解释器是非线程安全的.这意味着当从线程内尝试安全的访问Python对象的时候将有一个全局的强制锁.在任何时候,仅仅一个单一的线程能够获取Python对象或者C API.每100个字节的Python指令解释器将重新获取锁,这(潜在的)阻塞了I/O操作.因此CPU密集型的代码使用线程库时,不会获得性能的提高.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用concurrent.futures进行高层抽象的多线程操作\n",
    "\n",
    "concurrent.futures提供两种编程模型:\n",
    "\n",
    "+ 并行任务模型\n",
    "    单独任务独立使用自己的过程和数据,多任务独立并行计算\n",
    "\n",
    "+ MapReduce模型\n",
    "    为各个线程分发数据执行相同的过程\n",
    "    \n",
    "\n",
    "### 并行任务模型\n",
    "\n",
    "这个模型使用submit提交任务到上下文管理器,之后使用返回对象的result()方法阻塞io等待任务完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor,as_completed\n",
    "from random import randrange\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcfour(key, in_bytes, loops=20):\n",
    "    \"\"\"rc4算法\"\"\"\n",
    "    kbox = bytearray(256)  # create key box\n",
    "    for i, car in enumerate(key):  # copy key and vector\n",
    "        kbox[i] = car\n",
    "    j = len(key)\n",
    "    for i in range(j, 256):  # repeat until full\n",
    "        kbox[i] = kbox[i-j]\n",
    "\n",
    "    # [1] initialize sbox\n",
    "    sbox = bytearray(range(256))\n",
    "\n",
    "    # repeat sbox mixing loop, as recommened in CipherSaber-2\n",
    "    # http://ciphersaber.gurus.com/faq.html#cs2\n",
    "    j = 0\n",
    "    for k in range(loops):\n",
    "        for i in range(256):\n",
    "            j = (j + sbox[i] + kbox[i]) % 256\n",
    "            sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "\n",
    "    # main loop\n",
    "    i = 0\n",
    "    j = 0\n",
    "    out_bytes = bytearray()\n",
    "\n",
    "    for car in in_bytes:\n",
    "        i = (i + 1) % 256\n",
    "        # [2] shuffle sbox\n",
    "        j = (j + sbox[i]) % 256\n",
    "        sbox[i], sbox[j] = sbox[j], sbox[i]\n",
    "        # [3] compute t\n",
    "        t = (sbox[i] + sbox[j]) % 256\n",
    "        k = sbox[t]\n",
    "        car = car ^ k\n",
    "        out_bytes.append(car)\n",
    "\n",
    "    return out_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.47s\n",
      "elapsed time: 0.95s\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "clear = bytearray(b'1234567890' * 100000)\n",
    "t0 = time()\n",
    "cipher = arcfour(b'key', clear)\n",
    "print('elapsed time: %.2fs' % (time() - t0))\n",
    "result = arcfour(b'key', cipher)\n",
    "assert result == clear, '%r != %r' % (result, clear)\n",
    "print('elapsed time: %.2fs' % (time() - t0))\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crypto_process(size, key):\n",
    "    in_text = bytearray(randrange(256) for i in range(size))\n",
    "    cypher_text = arcfour(key, in_text)\n",
    "    out_text = arcfour(key, cypher_text)\n",
    "    assert in_text == out_text, 'Failed arcfour_test'\n",
    "    return size\n",
    "    \n",
    "def main(workers=None):\n",
    "    JOBS = 12\n",
    "    SIZE = 2**18\n",
    "\n",
    "    KEY = b\"'Twas brillig, and the slithy toves\\nDid gyre\"\n",
    "    STATUS = '{} workers, elapsed time: {:.2f}s'\n",
    "    if workers:\n",
    "        workers = int(workers)\n",
    "    t0 = time()\n",
    "\n",
    "    with ThreadPoolExecutor(workers) as executor:\n",
    "        actual_workers = executor._max_workers\n",
    "        to_do = []\n",
    "        for i in range(JOBS, 0, -1):\n",
    "            size = SIZE + int(SIZE / JOBS * (i - JOBS/2))\n",
    "            job = executor.submit(crypto_process, size, KEY)\n",
    "            to_do.append(job)\n",
    "\n",
    "        for future in as_completed(to_do):\n",
    "            res = future.result()\n",
    "            print('{:.1f} KB'.format(res/2**10))\n",
    "\n",
    "    print(STATUS.format(actual_workers, time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384.0 KB\n",
      "362.7 KB\n",
      "341.3 KB\n",
      "320.0 KB\n",
      "298.7 KB\n",
      "277.3 KB\n",
      "256.0 KB\n",
      "234.7 KB\n",
      "213.3 KB\n",
      "192.0 KB\n",
      "170.7 KB\n",
      "149.3 KB\n",
      "1 workers, elapsed time: 5.74s\n"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.7 KB\n",
      "384.0 KB\n",
      "320.0 KB\n",
      "341.3 KB\n",
      "298.7 KB\n",
      "277.3 KB\n",
      "234.7 KB\n",
      "256.0 KB\n",
      "192.0 KB\n",
      "213.3 KB\n",
      "170.7 KB\n",
      "149.3 KB\n",
      "2 workers, elapsed time: 5.90s\n"
     ]
    }
   ],
   "source": [
    "main(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341.3 KB\n",
      "320.0 KB\n",
      "362.7 KB\n",
      "384.0 KB\n",
      "234.7 KB\n",
      "277.3 KB\n",
      "256.0 KB\n",
      "298.7 KB\n",
      "170.7 KB\n",
      "149.3 KB\n",
      "192.0 KB\n",
      "213.3 KB\n",
      "4 workers, elapsed time: 6.13s\n"
     ]
    }
   ],
   "source": [
    "main(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce模型\n",
    "\n",
    "这种模式可能更加被大家熟悉,同一个流程,将容器中的数据一条一脚放入子进程运算,最终也结果也会被放入容器中.最后可以将收集来的数据在主进程中进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "def is_prime(n):\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, False]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[is_prime(i) for i in PRIMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessPool_prime(PRIMES= PRIMES ,workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        total = []\n",
    "        for prime in executor.map(is_prime, PRIMES):\n",
    "            #print('%d is prime: %s' % (number, prime))\n",
    "            total.append(prime)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, False]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProcessPool_prime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用线程池进行相对底层的多进程操作\n",
    "\n",
    "线程池的方式很适合批量创建子线程.线程池模块藏在多进程模块`multiprocessing.pool`下,`ThreadPool`\n",
    "\n",
    "对ThreadPool对象调用`join()`方法会等待所有子进程执行完毕,调用`join()`之前必须先调用`close()`，调用`close()`之后就不能继续添加新的Process了.\n",
    "\n",
    "\n",
    "请注意输出的结果,task 0,1,2,3是立刻执行的,而task 4要等待前面某个task完成后才执行,这是因为Pool的默认大小在我的电脑上是4，因此，最多同时执行4个进程.这是Pool有意设计的限制,并不是操作系统的限制.如果改成`p = Pool(5)`就可以同时跑5个进程.\n",
    "\n",
    "\n",
    "由于Pool的默认大小是CPU的核数,如果你不幸拥有8核CPU,你要提交至少9个子进程才能看到上面的等待效果.\n",
    "\n",
    "\n",
    "除了使用apply_async方法外,还有apply,map和map_async可以用于线程池的计算,编程模型也是如concurrent.futures一样分为两类\n",
    "\n",
    "+ 并行任务模型\n",
    "\n",
    "    + `apply` 单一任务布置\n",
    "    + `apply_async` 非阻塞单一任务布置\n",
    "    \n",
    "+ MapReduce模型\n",
    "\n",
    "    + `map` 同系统的map方法\n",
    "    + `map_async` 非阻塞的map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import os, time, random\n",
    "\n",
    "def long_time_task(name):\n",
    "    print('运行任务 %s (%s)...' % (name, os.getpid()))\n",
    "    start = time.time()\n",
    "    time.sleep(random.random() * 3)\n",
    "    end = time.time()\n",
    "    print('任务 %s 执行了 %0.2f 秒.' % (name, (end - start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "父线程 36193.\n",
      "等待所有子线程完成...\n",
      "运行任务 0 (36193)...运行任务 1 (36193)...运行任务 2 (36193)...运行任务 3 (36193)...\n",
      "\n",
      "\n",
      "\n",
      "任务 0 执行了 1.00 秒.\n",
      "运行任务 4 (36193)...\n",
      "任务 3 执行了 1.13 秒.\n",
      "任务 2 执行了 2.02 秒.\n",
      "任务 1 执行了 2.81 秒.\n",
      "任务 4 执行了 1.93 秒.\n",
      "所有子线程完成了.\n"
     ]
    }
   ],
   "source": [
    "print('父线程 %s.' % os.getpid())\n",
    "p = Pool(4)\n",
    "for i in range(5):\n",
    "    p.apply_async(long_time_task, args=(i,))#创建非阻塞子线程用这个\n",
    "print('等待所有子线程完成...')\n",
    "p.close()\n",
    "p.join()\n",
    "print('所有子线程完成了.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map:  [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "imap:\n",
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "25\n",
      "36\n",
      "49\n",
      "64\n",
      "81\n",
      "apply: 100\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2fd51c1360c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# make worker sleep for 10 secs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# raises multiprocessing.TimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "from time import sleep\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "# start 4 worker processes\n",
    "pool = Pool(processes=4)\n",
    "print(\"map: \",pool.map(f, range(10)))\n",
    "print(\"imap:\")\n",
    "for i in pool.imap_unordered(f, range(10)):\n",
    "    print(i)\n",
    "\n",
    "# evaluate \"f(10)\" asynchronously\n",
    "res = pool.apply_async(f, [10])\n",
    "print(\"apply:\",res.get(timeout=1))             # prints \"100\"\n",
    "\n",
    "# make worker sleep for 10 secs\n",
    "res = pool.apply_async(sleep, [10])\n",
    "print(res.get(timeout=1))             # raises multiprocessing.TimeoutError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取进程池中的运算结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msg: hello 0\n",
      "msg: hello 1\n",
      "msg: hello 2\n",
      "end\n",
      "end\n",
      "end\n",
      "::: done hello 0\n",
      "::: done hello 1\n",
      "::: done hello 2\n",
      "Sub-process(es) done.\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "import time\n",
    "\n",
    "def func(msg):\n",
    "    print(\"msg:\", msg)\n",
    "    time.sleep(1)\n",
    "    print(\"end\")\n",
    "    return \"done \" + msg\n",
    "\n",
    "\n",
    "pool = Pool(processes=4)\n",
    "result = []\n",
    "for i in range(3):\n",
    "    msg = \"hello %d\" %(i)\n",
    "    result.append(pool.apply_async(func, (msg, )))\n",
    "pool.close()\n",
    "pool.join()\n",
    "for res in result:\n",
    "    print(\":::\", res.get())\n",
    "print(\"Sub-process(es) done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更底层的多线程编程\n",
    "\n",
    "`threading`模块提供了一个高层的API来提供线程的并发性.这些线程并发运行并共享内存.多线程看着多么美好的,但因为数据安全的问题被加了锁.所以永远是单核运行,不细说了看个简单的用法吧\n",
    "\n",
    "下面来看threading模块的具体用法:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "\n",
      "2\n",
      "3\n",
      "4closed\n",
      "\n",
      "AWAKEAWAKE\n",
      "\n",
      "AWAKEAWAKEAWAKE\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def worker(i):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "    print(\"AWAKE\")\n",
    "\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker,args=(i,))\n",
    "    t.start()\n",
    "print(\"closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比下不用多线程:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "AWAKE\n",
      "1\n",
      "AWAKE\n",
      "2\n",
      "AWAKE\n",
      "3\n",
      "AWAKE\n",
      "4\n",
      "AWAKE\n"
     ]
    }
   ],
   "source": [
    "def worker(i):\n",
    "    print(i)\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    print(\"AWAKE\")\n",
    "\n",
    "for i in range(5):\n",
    "    worker(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个相对复杂的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "父线程 36193.\n",
      "子线程要开始啦.\n",
      "子线程 test (36193)...\n",
      "子线程 test (36193)...父线程36193进行中...\n",
      "父线程36193进行中...\n",
      "父线程36193进行中...\n",
      "\n",
      "子线程 test (36193)...\n",
      "子线程结束.\n",
      "父线程结束啦\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import os\n",
    "#子线程要执行的代码\n",
    "def run_proc(name):\n",
    "    for i in range(3):\n",
    "        print(u'子线程 %s (%s)...' % (name, os.getpid()))\n",
    "    print(u'子线程结束.')\n",
    "\n",
    "print(u'父线程 {}.'.format(os.getpid()))\n",
    "p = Thread(target=run_proc, args=('test',))\n",
    "print(u'子线程要开始啦.')\n",
    "p.start()\n",
    "for i in range(3):\n",
    "    print(u'父线程{pid}进行中...'.format(pid = os.getpid()))\n",
    "p.join()\n",
    "print(u\"父线程结束啦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Thread作为父类自定义子线程\n",
    "\n",
    "Thread的子类需要重写run方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: Thread idx=0 is called 'Thread-31'\n",
      "RESULT: Thread idx=1 is called 'Thread-32'\n",
      "RESULT: Thread idx=2 is called 'Thread-33'\n",
      "RESULT: Thread idx=3 is called 'Thread-34'\n",
      "RESULT: Thread idx=4 is called 'Thread-35'\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "class Processor(Thread):\n",
    "\n",
    "    def __init__(self, queue, idx):\n",
    "        super(Processor, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.idx = idx\n",
    "\n",
    "    def return_name(self):\n",
    "        ## NOTE: self.name is an attribute of multiprocessing.Process\n",
    "        return \"Thread idx=%s is called '%s'\" % (self.idx, self.name)\n",
    "\n",
    "    def run(self):\n",
    "        self.queue.put(self.return_name())\n",
    "        \n",
    "processes = list()\n",
    "q = Queue()\n",
    "for i in range(0,5):\n",
    "    p=Processor(queue=q, idx=i)\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "for proc in processes:\n",
    "    proc.join()\n",
    "    ## NOTE: You cannot depend on the results to queue / dequeue in the\n",
    "    ## same order\n",
    "    print(\"RESULT: {}\".format(q.get()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建子线程时,只需要传入一个执行函数和函数的参数,创建一个Thread实例,用`start()`方法启动,这样创建进程比`fork()`简单.\n",
    "\n",
    "`join()`方法可以等待子线程结束后再继续往下运行,通常用于线程间的同步.\n",
    "\n",
    "可以看到我们的父线程进行完了子线程才进行.其实当执行start方法的时候我们就已经把线程创建好并给他任务了.虽然线程启动了,但我们并不能知道它啥时候运算完成.这时候用join方法来确认是否执行完了(通过阻塞主线程),也就是起个等待结果的作用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用队列管理线程\n",
    "\n",
    "线程安全是多线程编程中最不容易的事儿,线程间同步,互斥数据共享一直是要考虑的问题,而最常见的就是用队列实现管理线程了.\n",
    "\n",
    "### 生产者消费者模型\n",
    "队列最常见的用处就是在生产者消费者模式中作为数据缓冲区.以下就是一个生产者消费者模式的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue as Queue\n",
    "import threading\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Producer(threading.Thread):\n",
    "    \"\"\"生产者\"\"\"\n",
    "    def __init__(self,q,con,name):\n",
    "        super(Producer,self).__init__()\n",
    "        self.q = q\n",
    "        self.name = name\n",
    "        self.con = con\n",
    "        print(\"生产者{self.name}产生了\".format(self=self))\n",
    "\n",
    "    def run(self):\n",
    "        count = 3 #只生产满3轮,要不然就会无限循环出不去了\n",
    "        while count>0:\n",
    "            #global writelock\n",
    "            self.con.acquire()\n",
    "            if self.q.full():\n",
    "                print(\"队列满了,生产者等待\")\n",
    "                count-=1\n",
    "                self.con.wait()\n",
    "\n",
    "            else:\n",
    "                value = random.randint(0,10)\n",
    "                print(\"{self.name}把值{self.name}:{value}放入了队列\".format(self=self,value=value))\n",
    "                self.q.put(\"{self.name}:{value}\".format(self=self,value=value))\n",
    "            self.con.notify()\n",
    "        self.con.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Consumer(threading.Thread):\n",
    "    \"\"\"消费者\"\"\"\n",
    "    def __init__(self,q,con,name):\n",
    "        super(Consumer,self).__init__()\n",
    "        self.q = q\n",
    "        self.name = name\n",
    "        self.con = con\n",
    "        print(\"消费者{self.name}产生了\".format(self=self))\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            #global writelock\n",
    "            self.con.acquire()\n",
    "            if self.q.empty():\n",
    "\n",
    "                print(\"队列空了,消费者等待\")\n",
    "                self.con.wait()\n",
    "            else:\n",
    "                value = self.q.get()\n",
    "\n",
    "                print(\"{self.name}从队列中获取了{self.name}:{value}\".format(self=self,\n",
    "                                                                         value=value))\n",
    "                self.con.notify()\n",
    "            self.con.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生产者P1产生了\n",
      "P1把值P1:10放入了队列生产者P2产生了\n",
      "\n",
      "P1把值P1:10放入了队列\n",
      "P1把值P1:2放入了队列\n",
      "P1把值P1:10放入了队列\n",
      "P1把值P1:1放入了队列\n",
      "消费者C1产生了\n",
      "P1把值P1:6放入了队列\n",
      "P1把值P1:9放入了队列\n",
      "P1把值P1:3放入了队列\n",
      "P1把值P1:4放入了队列\n",
      "P1把值P1:4放入了队列\n",
      "队列满了,生产者等待\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:10\n",
      "C1从队列中获取了C1:P1:10\n",
      "C1从队列中获取了C1:P1:2\n",
      "C1从队列中获取了C1:P1:10\n",
      "C1从队列中获取了C1:P1:1\n",
      "C1从队列中获取了C1:P1:6\n",
      "C1从队列中获取了C1:P1:9\n",
      "C1从队列中获取了C1:P1:3\n",
      "C1从队列中获取了C1:P1:4\n",
      "C1从队列中获取了C1:P1:4\n",
      "队列空了,消费者等待\n",
      "P1把值P1:7放入了队列\n",
      "P1把值P1:8放入了队列\n",
      "P1把值P1:9放入了队列\n",
      "P1把值P1:10放入了队列\n",
      "P1把值P1:1放入了队列\n",
      "P1把值P1:7放入了队列\n",
      "P1把值P1:9放入了队列\n",
      "P1把值P1:10放入了队列\n",
      "P1把值P1:4放入了队列\n",
      "P1把值P1:1放入了队列\n",
      "队列满了,生产者等待\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:7\n",
      "C1从队列中获取了C1:P1:8\n",
      "C1从队列中获取了C1:P1:9\n",
      "C1从队列中获取了C1:P1:10\n",
      "C1从队列中获取了C1:P1:1\n",
      "P2把值P2:10放入了队列\n",
      "P2把值P2:1放入了队列\n",
      "P2把值P2:10放入了队列\n",
      "P2把值P2:1放入了队列\n",
      "P2把值P2:4放入了队列\n",
      "队列满了,生产者等待\n",
      "队列满了,生产者等待\n",
      "C1从队列中获取了C1:P1:7\n",
      "C1从队列中获取了C1:P1:9\n",
      "C1从队列中获取了C1:P1:10\n"
     ]
    }
   ],
   "source": [
    "q = Queue.Queue(10)\n",
    "con = threading.Condition()\n",
    "p1 = Producer(q,con,\"P1\")\n",
    "p1.start()\n",
    "p2 = Producer(q,con,\"P2\")\n",
    "p2.start()\n",
    "c1 = Consumer(q,con,\"C1\")\n",
    "c1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queue模块说明\n",
    "\n",
    "队列类型 \n",
    "\n",
    "+ `queue.Queue(maxsize)`先进先出队列,maxsize是队列长度,其值为非正数时是无限循环队列\n",
    "\n",
    "+ `queue.LifoQueue(maxsize)` 后进先出队列,也就是栈\n",
    "+ `queue.PriorityQueue(maxsize)` 优先级队列\n",
    "\n",
    "\n",
    "支持方法\n",
    "\n",
    "+ `qsize()` 返回近似队列大小,,用近似二字因为当该值大于0时不能保证并发执行的时候get(),put()方法不被阻塞\n",
    "+ `empty()` 判断是否为空,空返回True否则返回False\n",
    "+ `full()` 当设定了队列大小的时候,如果队列满了则返回True,否则False\n",
    "+ `put(item[,block[,timeout]])` 向队列添加元素\n",
    "    + 当block设置为False时队列满则抛出异常\n",
    "    + 当block为True,timeout为None时则会等待直到有空位\n",
    "    + 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误\n",
    "+ `put_nowait(item)` 相当于put(item,False)\n",
    "+ `get([,block[,timeout])` 从队列中取出元素,\n",
    "    + 当block设置为False时队列空则抛出异常\n",
    "    + 当block为True,timeout为None时则会等待直到有+元素\n",
    "    + 当block为True,timeout不为None时则根据设定的时间判断是否等待,超时了就抛出错误\n",
    "+ `get_nowait()` 等价于get(False)\n",
    "+ `task_done()` 发送信号表明入列任务已经完成,常在消费者线程里使用\n",
    "+ `join()` 阻塞直到队列中所有元素处理完\n",
    "\n",
    "Queue是线程安全的,而且支持in操作,因此用它的时候不用考虑锁的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Unix信号\n",
    "\n",
    "标准库`signal`提供了操作Unix信号的方法.需要注意signal模块主要是针对Unix平台(linux,osx).Windows上的Python不能发挥signal模块的功能.\n",
    "\n",
    "常见的信号可以查看本章的结语部分.\n",
    "\n",
    "Python信号处理程序总是在主线程中执行.这意味着信号不能用作线程间通信的手段.同时也只允许主线程设置新的信号处理程序."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用信号处理函数\n",
    "\n",
    "+ 设置发送SIGALRM信号的定时器\n",
    "\n",
    "`signal.alarm(time)`可以设置一个发送`SIGALRM`信号的定时器,在time秒后就会发送这个信号量到进程,在不做处理的情况下进程会退出\n",
    "\n",
    "\n",
    "+ 使用`signal.pasue`阻塞函数\n",
    "\n",
    "`signal.pasue`会让主线程暂停以等待信号,接收到信号后使进程停止\n",
    "\n",
    "+ `signal.signal(sig,handler)`用于注册收到信号后的处理函数\n",
    "\n",
    "注意handler函数有两个参数--信号number和帧对象\n",
    "\n",
    "\n",
    "下面这个例子我们演示了监听信号的过程,无论是等待10s还是使用`ctrl+C`都可以中断阻塞使程序结束."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/signal_pasue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/signal_pasue.py\n",
    "import signal\n",
    "signal.signal(signal.SIGALRM,lambda sig,frame:print(\"闹钟!\"))\n",
    "signal.signal(signal.SIGINT,lambda sig,frame:print(\"ctrl+C!\"))\n",
    "signal.alarm(10)\n",
    "print(\"开始等待信号\")\n",
    "signal.pause()\n",
    "print(\"等待结束\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多线程中使用信号\n",
    "\n",
    "\n",
    "+ `signal.sigwait(sigset)`用于在子线程中等待`sigset`中定义的多个信号之一,一旦受到信号就取消阻塞向下走\n",
    "+ `signal.pthread_kill(thread_id, signal.SIGCONT)`用于在主线程中发送消息到子线程.thread_id可以通过运行中的子线程的`ident`属性获得.\n",
    "\n",
    "下面的例子演示了主线程向子线程发送信号的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/signal_multithread.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/signal_multithread.py\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import signal\n",
    "\n",
    "def worker(i):\n",
    "    print(f\"worker {i} waiting for SIGCONT\")\n",
    "    signal.sigwait({signal.SIGCONT})\n",
    "    print(f\"end worker thread {i}\")\n",
    "\n",
    "\n",
    "workers = {}\n",
    "for i in range(5):\n",
    "    t = threading.Thread(target=worker, args=(i,))\n",
    "    t.start()\n",
    "    workers[t.ident] = t\n",
    "\n",
    "time.sleep(1)\n",
    "chose = random.choice(list(workers.keys()))\n",
    "print(f\"send to tid {chose}\")\n",
    "signal.pthread_kill(chose, signal.SIGCONT)\n",
    "print(\"closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线程变协程\n",
    "\n",
    "在Python3.4之前python没有原生的协程那个时候有一个神级的协程库[gevent](http://www.gevent.org/contents.html)它可以通过[monkey patch](http://blog.hszofficial.site/TutorialForPython/%E8%AF%AD%E6%B3%95%E7%AF%87/%E5%85%83%E7%BC%96%E7%A8%8B/%E7%8C%B4%E5%AD%90%E8%A1%A5%E4%B8%81%E5%92%8C%E7%83%AD%E6%9B%B4%E6%96%B0.html)将标准库替换从而实现线程变协程,替换的库在[这个文档中](http://www.gevent.org/api/gevent.monkey.html#gevent.monkey.patch_all)有汇总.gevent至今依然被广泛使用,也是最推荐的协程使用方式之一."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/gvt_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/gvt_test.py\n",
    "from gevent import monkey; monkey.patch_all()\n",
    "import threading\n",
    "import queue\n",
    "import socket\n",
    "print(socket.socket)\n",
    "\n",
    "class Processor(threading.Thread):\n",
    "\n",
    "    def __init__(self, queue, idx):\n",
    "        super(Processor, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.idx = idx\n",
    "\n",
    "    def return_name(self):\n",
    "        ## NOTE: self.name is an attribute of multiprocessing.Process\n",
    "        return \"Thread idx=%s is called '%s'\" % (self.idx, self.name)\n",
    "\n",
    "    def run(self):\n",
    "        self.queue.put(self.return_name())\n",
    "        \n",
    "processes = list()\n",
    "q = queue.Queue()\n",
    "for i in range(0,5):\n",
    "    p=Processor(queue=q, idx=i)\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "for proc in processes:\n",
    "    proc.join()\n",
    "    ## NOTE: You cannot depend on the results to queue / dequeue in the\n",
    "    ## same order\n",
    "    print(\"RESULT: {}\".format(q.get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gevent._socket3.socket'>\r\n",
      "RESULT: Thread idx=0 is called 'Thread-1'\r\n",
      "RESULT: Thread idx=1 is called 'Thread-2'\r\n",
      "RESULT: Thread idx=2 is called 'Thread-3'\r\n",
      "RESULT: Thread idx=3 is called 'Thread-4'\r\n",
      "RESULT: Thread idx=4 is called 'Thread-5'\r\n"
     ]
    }
   ],
   "source": [
    "!python src/gvt_test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
